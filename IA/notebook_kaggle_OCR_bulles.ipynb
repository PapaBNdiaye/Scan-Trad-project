{
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.11",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "sourceId": 12056817,
     "sourceType": "datasetVersion",
     "datasetId": 7588298
    }
   ],
   "dockerImageVersionId": 31041,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook",
   "isGpuEnabled": true
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "import cv2\n",
    "import pytesseract\n",
    "import imutils\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n",
    "\n",
    "\n",
    "def yolo_to_pixel(cx_norm, cy_norm, w_norm, h_norm, img_width, img_height):\n",
    "    \"\"\"\n",
    "    Convertit les coordonnées normalisées YOLO en coordonnées en pixels (xmin, ymin, xmax, ymax).\n",
    "\n",
    "    Args:\n",
    "        cx_norm (float): Position x du centre (normalisé)\n",
    "        cy_norm (float): Position y du centre (normalisé)\n",
    "        w_norm (float): Largeur de la box (normalisée)\n",
    "        h_norm (float): Hauteur de la box (normalisée)\n",
    "        img_width (int): Largeur de l'image\n",
    "        img_height (int): Hauteur de l'image\n",
    "\n",
    "    Returns:\n",
    "        tuple: (xmin, ymin, xmax, ymax) en pixels\n",
    "    \"\"\"\n",
    "    cx = cx_norm * img_width\n",
    "    cy = cy_norm * img_height\n",
    "    w = w_norm * img_width\n",
    "    h = h_norm * img_height\n",
    "\n",
    "    xmin = int(cx - w / 2)\n",
    "    ymin = int(cy - h / 2)\n",
    "    xmax = int(cx + w / 2)\n",
    "    ymax = int(cy + h / 2)\n",
    "\n",
    "    return xmin, ymin, xmax, ymax\n",
    "\n",
    "\n",
    "def get_texts(path_image, boxes, newW, newH, padding=0):\n",
    "    \n",
    "    # load the input image and grab the image dimensions\n",
    "    image = cv2.imread(path_image) \n",
    "    orig = image.copy()\n",
    "    (origH, origW) = image.shape[:2]\n",
    "    # set the new width and height and then determine the ratio in change\n",
    "    # for both the width and height\n",
    "    rW = origW / float(newW)\n",
    "    rH = origH / float(newH)\n",
    "    # resize the image and grab the new image dimensions\n",
    "    image = cv2.resize(image, (newW, newH))\n",
    "    (H, W) = image.shape[:2]\n",
    "\n",
    "\n",
    "    # initialize the list of results\n",
    "    results = []\n",
    "    # loop over the bounding boxes\n",
    "    for (centerX, centerY, width, heigth) in boxes:\n",
    "        startX, startY, endX, endY = yolo_to_pixel(centerX, centerY, width, heigth, newW, newH)\n",
    "    \t# scale the bounding box coordinates based on the respective\n",
    "    \t# ratios\n",
    "        startX = int(startX * rW)\n",
    "        startY = int(startY * rH)\n",
    "        endX = int(endX * rW)\n",
    "        endY = int(endY * rH)\n",
    "    \t# in order to obtain a better OCR of the text we can potentially\n",
    "    \t# apply a bit of padding surrounding the bounding box -- here we\n",
    "    \t# are computing the deltas in both the x and y directions\n",
    "        dX = int((endX - startX) * padding)\n",
    "        dY = int((endY - startY) * padding)\n",
    "        # apply padding to each side of the bounding box, respectively\n",
    "        startX = max(0, startX - dX)\n",
    "        startY = max(0, startY - dY)\n",
    "        endX = min(origW, endX + (dX * 2))\n",
    "        endY = min(origH, endY + (dY * 2))\n",
    "        # extract the actual padded ROI\n",
    "        roi = orig[startY:endY, startX:endX]\n",
    "        \n",
    "        # in order to apply Tesseract v4 to OCR text we must supply\n",
    "        # (1) a language, (2) an OEM flag of 1, indicating that the we\n",
    "        # wish to use the LSTM neural net model for OCR, and finally\n",
    "        # (3) an OEM value, in this case, 7 which implies that we are\n",
    "        # treating the ROI as a single line of text\n",
    "        config = (\"-l eng --psm 6\")\n",
    "        text = pytesseract.image_to_string(roi, config=config)\n",
    "        # add the bounding box coordinates and OCR'd text to the list\n",
    "        # of results\n",
    "        results.append([(startX, startY, endX, endY), text])\n",
    "    \n",
    "    # sort the results bounding box coordinates from top to bottom\n",
    "    results = sorted(results, key=lambda r:r[0][1])\n",
    "    # loop over the results\n",
    "    for index,(((startX, startY, endX, endY), text)) in enumerate(results):\n",
    "    \tboxes[index].append(\"\".join([c if ord(c) < 128 else \"\" for c in text]).strip())\n",
    "    print(boxes)\n",
    "\n",
    "\n",
    "#variables pour l'exemple\n",
    "path_image = \"/kaggle/input/images/DS_2_jpg.rf.0070a2c64c6c6389ab8bbcc4c8d0287b.jpg\"\n",
    "(newW, newH) = (640, 640) \n",
    "padding = 0\n",
    "boxes = [\n",
    "    [0.44609375, 0.11484375, 0.2265625, 0.12734375],\n",
    "    [0.86328125, 0.14921875, 0.225, 0.11015625],\n",
    "    [0.39140625, 0.303125, 0.1828125, 0.10546875]\n",
    "]\n",
    "\n",
    "# get_texts(path_image,boxes, newW, newH) exemple de l'appel de la fonction"
   ],
   "metadata": {
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-06-04T10:46:27.814788Z",
     "iopub.execute_input": "2025-06-04T10:46:27.815482Z",
     "iopub.status.idle": "2025-06-04T10:46:28.323284Z",
     "shell.execute_reply.started": "2025-06-04T10:46:27.815457Z",
     "shell.execute_reply": "2025-06-04T10:46:28.322580Z"
    },
    "is_executing": true
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ]
}
